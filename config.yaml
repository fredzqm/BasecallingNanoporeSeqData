trainingInput:
  scaleTier: BASIC_GPU
  # masterType: standard_gpu
  # workerType: standard_gpu
  # parameterServerType: standard
  hyperparameters:
    goal: MAXIMIZE
    maxTrials: 2
    maxParallelTrials: 1
    params:
    - parameterName: early-stop-patience
      type: INTEGER
      minValue: 5
      maxValue: 30
      scaleType: UNIT_LINEAR_SCALE
    - parameterName: train-batch-size
      type: INTEGER
      minValue: 70
      maxValue: 500
      scaleType: UNIT_LOG_SCALE
    - parameterName: num-layers
      type: INTEGER
      minValue: 4
      maxValue: 10
      scaleType: UNIT_LINEAR_SCALE
    - parameterName: first-layer-size
      type: INTEGER
      minValue: 90
      maxValue: 300
      scaleType: UNIT_LOG_SCALE
    - parameterName: scale-factor
      type: DOUBLE
      minValue: 0.5
      maxValue: 0.9
      scaleType: UNIT_REVERSE_LOG_SCALE
    # - parameterName: first-layer-dropout-rate
    #   type: INTEGER
    #   minValue: 0.05
    #   maxValue: 0.6
    #   scaleType: UNIT_LINEAR_SCALE
    # - parameterName: dropout-rate-scale-factor
    #   type: DOUBLE
    #   minValue: 0.5
    #   maxValue: 1
    #   scaleType: UNIT_REVERSE_LOG_SCALE
    hyperparameterMetricTag: acc
trainingOutput:
  isHyperparameterTuningJob: True
